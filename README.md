
#Coding Medical specialty from Transcription

The transcription tell us about the medical case , however the medical term that refer to the complete transcription is the medical specialty and that is more close to the standard medical term . Our task is here to map correct medical specialty to the corresponding transcription.



**D A T A E X P L O R A T I O N**

        • **Pandas Profiling:** It save us all the work of visualizing and understanding the distribution of each variable. It

        generates a report with all the information easily available. It tells us

                • Variables that contain NaN values and variables with many zeros

                • Correlations and variables with high cardinality

                • Total characters, unique words, words with frequencies, lowercase, upper case, Punctuation, etc.

                • Identify languages from text

                • Generate histogram

        • **Value\_counts() with Bar\_chart:** It shows the count of each category in the Package column. This helps us to

        identify class imbalance problem associated with the dataset

        • **Dependency Visualization:** Here we used scispaCy, a SpaCy model to visualize which pre-trained models will work

        best for our problem. scispaCy is a Python package containing spaCy models for processing biomedical, scientific or

        clinical text.

        • **Rough\_work:** This space was used in parallel to choose the best-performing techniques from Bag-of-Words, TF-IDF,

        CountVectorizer, and Word-to-Vector along with machine learning algorithms





**D A T A M O D E L I N G : A P P R O A C H \_ 1**

        • **Step\_1: clean\_text**

                • For text cleaning, we have used the report generated by **Pandas Profiling** to get the insight of punctuation, Math Symbols, other symbols, space, etc.

        • **Step\_2: lemmatize\_text with nltk**

                • Lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors

                • ‘Caring’ -> Lemmatization -> ‘Care’ ‘Caring’ -> Stemming -> ‘Car’ , Here we are dealing with medical'sterminology. So the base meaning is very important

        • **Step\_3: TfidfVectorizer (term frequency–inverse document frequency)**

                • Tf-Idf, evaluates how relevant a word is to a document in a collection of documents.

                • The **TfidfVectorizer(**CountVectorizer + TfidfTransformer **)** will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents

                • **TfidfVectorizer** give the sparse matrix in the following format: (A,B) C

                    • A: Document index B: Specific word-vector index C: TFIDF score for word B in document A

                    • It indicates the tfidf score for all non-zero values in the word vector for each document.

        • **Step\_4: PCA(Principal Component Analysis)**

                • PCA is a solution to the highly redundant features problem. It is suitable in our case because **TfidfVectorizer** generates 500+ features

                • The PCA model assumes that the data has a continuous distribution over +/- infinity. NLP data on the other hand, typically has a discrete distribution or a multinomial distribution because the data is based on discrete counts of events or lexical symbols. PCA will do a very poor job of reconstruction discrete data because the values can go negative.

                • "non-negative matrix factorization" (NMF), "probabilistic latent semantic analysis" (PLSA) and "probabilistic latent Dirichlet analysis" (PLDA).

        • **Step\_5: Data Modelling:**

                • Here we simply use the LogisticRegression() to check for the accuracy matrix and to understand the impact of the above steps.

                • **Result: Accuracy = 64%**





**D A T A M O D E L I N G : A P P R O A C H \_ 2**

        • **Step\_0: clean\_text with SciSpaCy**

                • scispaCy is a powerful tool, especially for named entity recognition (NER), or identifying keywords (called entities) and ordering them into categories

                • Pre-process the data using scispacy “**en\_core\_sci\_md**” model to detect medical entities in description

        • **Step\_2: lemmatize\_text with nltk:**

        • **Step\_3: TfidfVectorizer (term frequency–inverse document frequency)**

        • **Step\_4: PCA(Principal Component Analysis)**

        • **Step\_5: Data Modelling:**

                • Here we have tested several models to identify the best performing model, the impact of the above steps and what can be done next to increase the performance

                • LogisticRegression() gives the highest accuracy but after visualizing the results from several models we can see that the classes with a lower countdecrease the performance, **Class imbalance problem**

                • **Result: Accuracy = 78%**





**D A T A M O D E L I N G : A P P R O A C H \_ 3**

        • **Step\_0: clean\_text with SciSpaCy**

        • **Step\_2: lemmatize\_text with nltk:**

        • **Step\_3: TfidfVectorizer (term frequency–inverse document frequency)**

        • **Step\_4: PCA(Principal Component Analysis)**

        • **Step\_4.1: Oversampling with SMOTE (Synthetic Minority Over-sampling Technique )**

                • Since some classes are in minority. So we can use SMOTE to generate more sample form minority class to solve the data imbalance problem

        • **Step\_5: Data Modelling:**

                • Here we use the best performing model, LogisticRegression() to check for the accuracy matrix and to understand the impact of the above steps.

                • **Result: Accuracy = 81%**





**D A T A M O D E L I N G : A P P R O A C H \_ 4**

        • **Step\_0: clean\_text with SciSpaCy**

        • **Step\_2: lemmatize\_text with nltk:**

        • **Step\_3: TfidfVectorizer (term frequency–inverse document frequency)**

        • **Step\_4: PCA(Principal Component Analysis)**

        • **Step\_4.1: Oversampling with SMOTE (Synthetic Minority Over-sampling Technique )**

        • **Step\_5: Data Modelling:**

                • Here we tune the hyper parameters LogisticRegression() in order to increase the performance

                • We hit the highest accuracy of 83-84%. The fluctuation in the accuracy is due to SpaCy models and oversampling

                • **Result: Accuracy = 83-84%**





**C O N C L U S I O N**

        • The dataset is imbalance and lots of text in description overlaps across categories

        • Detailed analysis of metrics is used to understand better the specifics of how the algorithm works with different classes

        • Wider range of algorithms was tried in order to find the best one

        • For the existing algorithm, tuning has given some more fractions of a percent

        • We have achieved the highest accuracy of 83-84% with Logistic Regression followed by Multilayer perceptron with 82-81% of accuracy

        • The overall accuracy can be increased by using BioWordVec & BioSentVec models trained on PubMed+MIMIC-III, I'm not able to use these models because of hardware limitation

